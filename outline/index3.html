---
layout: full-width
title: Outline
---
<article>
  <h2>What is Data Science</h2>


  <p>The goal is now to provide a comprehensive guide to data science starting with an approach for small to <a href="http://svdictionary.com/words/medium-data">medium data</a>, and later outline big data analysis. It is more managable to learn the techniques with smaller data sets which fit in memory first, and then move onto analysis of very large datasets which might require multiple computers.</p>

  <p>While we attempt to be comprehensive, this guide is still a work in progress and we look foward to edits, improvements and suggetions. Please feel free to send us a <a href="https://github.com/datascienceguide/datascienceguide.github.io">pull request</a> (TODO: how to do a pull request)</p>

</article>
    <div class="module-header">Assignments</div>

    <div class="materials-item">
      <a href="assignment1/">
        Assignment #1: Image Classification, kNN, SVM, Softmax
      </a>
    </div>

    <div class="materials-item">
      <a href="assignment2/">
        Assignment #2: Neural Networks, ConvNets I
      </a>
    </div>

    <div class="materials-item">
      <a href="assignment3/">
        Assignment #3: ConvNets II, Transfer Learning, Visualization
      </a>
    </div>

    <div class="module-header">Module 0: Preparation</div>

    <div class="materials-item">
      <a href="python-numpy-tutorial/">
        Python / Numpy Tutorial
      </a>
    </div>

    <div class="materials-item">
      <a href="ipython-tutorial/">
        IPython Notebook Tutorial
      </a>
    </div>

    <div class="materials-item">
      <a href="terminal-tutorial/">
        Terminal.com Tutorial
      </a>
    </div>

    <!-- hardcoding items here to force a specific order -->
    <div class="module-header">Module 1: Neural Networks</div>

    <div class="materials-item">
      <a href="classification/">
        Image Classification: Data-driven Approach, k-Nearest Neighbor, train/val/test splits
      </a>
      <div class="kw">
        L1/L2 distances, hyperparameter search, cross-validation
      </div>
    </div>

    <div class="materials-item">
      <a href="linear-classify/">
        Linear classification: Support Vector Machine, Softmax
      </a>
      <div class="kw">
        parameteric approach, bias trick, hinge loss, cross-entropy loss, L2 regularization, web demo
      </div>
    </div>

    <div class="materials-item">
      <a href="optimization-1/">
        Optimization: Stochastic Gradient Descent
      </a>
      <div class="kw">
        optimization landscapes, local search, learning rate, analytic/numerical gradient
      </div>
    </div>

    <div class="materials-item">
      <a href="optimization-2/">
        Backpropagation, Intuitions
      </a>
      <div class="kw">
        chain rule interpretation, real-valued circuits, patterns in gradient flow
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-1/">
        Neural Networks Part 1: Setting up the Architecture
      </a>
      <div class="kw">
        model of a biological neuron, activation functions, neural net architecture, representational power
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-2/">
        Neural Networks Part 2: Setting up the Data and the Loss
      </a>
      <div class="kw">
        preprocessing, weight initialization, regularization, dropout, loss functions in the wild
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-3/">
        Neural Networks Part 3: Learning and Evaluation
      </a>
      <div class="kw">
        gradient checks, sanity checks, babysitting the learning process, momentum (+nesterov), second-order methods, Adagrad/RMSprop, hyperparameter optimization, model ensembles
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-case-study/">
        Putting it together: Minimal Neural Network Case Study
      </a>
      <div class="kw">
        minimal 2D toy data example
      </div>
    </div>

    <div class="module-header">Module 2: Convolutional Neural Networks</div>

    <div class="materials-item">
      <a href="convolutional-networks/">
        Convolutional Neural Networks: Architectures, Convolution / Pooling Layers
      </a>
      <div class="kw">
        layers, spatial arrangement, layer patterns, layer sizing patterns, AlexNet/ZFNet/VGGNet case studies, computational considerations
      </div>
    </div>

    <div class="materials-item">
      <a href="understanding-cnn/">
        Understanding and Visualizing Convolutional Neural Networks
      </a>
      <div class="kw">
        tSNE embeddings, deconvnets, data gradients, fooling ConvNets, human comparisons
      </div>
    </div>

    <div class="materials-item">
      <a href="transfer-learning/">
        Transfer Learning and Fine-tuning Convolutional Neural Networks
      </a>
    </div>

    <div class="materials-item notyet">
      <a href="convnet-tips/">
        ConvNet Tips and Tricks: squeezing out the last few percent
      </a>
      <div class="kw">
        multi-scale, model ensembles, data augmentations
      </div>
    </div>

    <div class="module-header">Module 3: ConvNets in the wild</div>

    <div class="materials-item notyet">
      <a href="">
        Other Visual Recognition Tasks: Localization, Detection, Segmentation
      </a>
    </div>

    <div class="materials-item notyet">
      <a href="">
        ConvNets in Practice: Distributed Training, GPU bottlenecks, Libraries
      </a>
    </div>

  </div>
</div>
